{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfacdbd",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true) <img src=\"https://github.com/PracticumAI/practicumai.github.io/blob/84b04be083ca02e5c7e92850f9afd391fc48ae2a/images/icons/practicumai_computer_vision.png?raw=true\" alt=\"Practicum AI: Computer Vision icon\" align=\"right\" width=50>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57fca5c",
   "metadata": {},
   "source": [
    "# Transfer Learning with Pre-trained Models\n",
    "\n",
    "In our previous notebooks, we built [CNN models from scratch](01.1_bees_vs_wasps.ipynb) and [explored data augmentation](01.2_data_augmentation.ipynb). While these techniques are valuable, training deep networks from scratch requires significant computational resources and large datasets. \n",
    "\n",
    "**Transfer Learning** offers a powerful alternative: we can leverage models that have already been trained on massive datasets and adapt them for our specific task.\n",
    "\n",
    "## What is Transfer Learning?\n",
    "\n",
    "Transfer learning involves taking a model that has been pre-trained on a large dataset (like ImageNet with 1.4 million images) and adapting it for a new, related task. The key insight is that the features learned by these models (edges, shapes, textures, objects) are often useful across many different computer vision tasks.\n",
    "\n",
    "Transfer learning is powerful, but it requires some understanding of how to effectively use pre-trained models. If you finish this notebook and want to learn more, check out *Practicum AI*'s Transfer Learning Intermediate Course. Our GitHub content can be found here: [Transfer Learning](https://github.com/PracticumAI/transfer_learning). Keep an eye out for our certification content on UF's Professional Workforce Development platform as well, found here: [PracticumAI Intermediate Series](https://pwd.aa.ufl.edu/ai/).\n",
    "\n",
    "\n",
    "## Benefits of Transfer Learning:\n",
    "\n",
    "1. **Faster Training**: Start with learned features instead of random weights\n",
    "2. **Better Performance**: Especially with limited data\n",
    "3. **Less Data Required**: Can achieve good results with smaller datasets\n",
    "4. **Computational Efficiency**: Don't need to train millions of parameters from scratch\n",
    "\n",
    "## EfficientNetB5\n",
    "\n",
    "For this notebook, we'll use **EfficientNetB5**, a state-of-the-art convolutional neural network that achieves excellent accuracy while being computationally efficient. EfficientNetB5:\n",
    "\n",
    "- Is one of a set of models published by Google engineers [Tan and Le in 2019](https://arxiv.org/abs/1905.11946).\n",
    "- Was trained on ImageNet (1.4M images, 1000 classes)\n",
    "- Uses compound scaling to balance network depth, width, and resolution\n",
    "- Achieves top-1 accuracy of ~83.6% on ImageNet\n",
    "- Has ~30 million parameters\n",
    "\n",
    "Let's see how this powerful pre-trained model performs on our bee vs wasp classification task!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb086d19",
   "metadata": {},
   "source": [
    "## 1. Import the libraries we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20379be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# For EfficientNet, we'll use timm (PyTorch Image Models)\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Many functions are moved to helpers_01.py to keep this file clean.\n",
    "import helpers_01\n",
    "\n",
    "# Set seed for reproducibility\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1570a0f3",
   "metadata": {},
   "source": [
    "## 2. Check PyTorch installation and available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae591f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Pytorch versions and check for GPU\n",
    "print(f\"Pytorch version: {torch.__version__}\")\n",
    "print(f'  Should be \"True\" if Pytorch was built for GPU: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  Available GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    print(\"  No GPU available, will use CPU\")\n",
    "\n",
    "# Check if timm is available and show EfficientNet models\n",
    "try:\n",
    "    print(f\"\\nTimm version: {timm.__version__}\")\n",
    "    # List available EfficientNet models (there are a bunch!)\n",
    "    efficientnet_models = [\n",
    "        model\n",
    "        for model in timm.list_models()\n",
    "        if \"efficientnet\" in model\n",
    "    ]\n",
    "    print(\n",
    "        f\"Available EfficientNetB5 variants: {efficientnet_models}\"\n",
    "    )  \n",
    "except ImportError:\n",
    "    print(\"Timm not available.\")\n",
    "    print(f\"Timm installed successfully: {timm.__version__}\")\n",
    "\n",
    "# Set the number of workers for data loading\n",
    "num_workers = None  # To manually set the number of workers, change this to an integer\n",
    "\n",
    "if num_workers is None:\n",
    "    # If Slurm is being used, set the number of workers to a Slurm-provided value.\n",
    "    # If Slurm is not being used, set the number of workers to the number of available CPU cores.\n",
    "    if os.getenv(\"SLURM_CPUS_PER_TASK\") is not None:\n",
    "        num_workers = int(os.getenv(\"SLURM_CPUS_PER_TASK\"))\n",
    "    elif os.getenv(\"SLURM_NTASKS_PER_NODE\") is not None:\n",
    "        num_workers = int(os.getenv(\"SLURM_NTASKS_PER_NODE\"))\n",
    "    elif os.getenv(\"SLURM_NTASKS\") is not None:\n",
    "        num_workers = int(os.getenv(\"SLURM_NTASKS\"))\n",
    "    else:\n",
    "        num_workers = os.cpu_count()\n",
    "\n",
    "print(f\"\\n\\nUsing {num_workers} workers for data loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d9c7a",
   "metadata": {},
   "source": [
    "## 3. Load and prepare the data\n",
    "\n",
    "We'll use the same bee vs wasp dataset, but this time we need to adjust our data preprocessing to match what EfficientNetB5 expects. Pre-trained models typically expect specific input sizes and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb35c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data path\n",
    "data_path = helpers_01.manage_data(folder_name=\"bee_vs_wasp_reduced\")\n",
    "\n",
    "\n",
    "# EfficientNetB5 expects 224x224 images (higher resolution than our previous models)\n",
    "# This is important for transfer learning - use the same input size as pre-training\n",
    "data_module = helpers_01.load_display_data_augmented(\n",
    "    data_path,\n",
    "    batch_size=16,  # Smaller batch size due to larger images and model\n",
    "    shape=(224, 224, 3),  # EfficientNetB5 standard input size\n",
    "    show_pictures=True,\n",
    "    train_split=0.8,\n",
    "    num_workers=num_workers,\n",
    "    augmentation_strength=\"light\",  # Start with light augmentation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda30c62",
   "metadata": {},
   "source": [
    "## 4. Understanding Transfer Learning Approaches\n",
    "\n",
    "There are several ways to use a pre-trained model:\n",
    "\n",
    "1. **Feature Extraction**: Freeze the pre-trained layers and only train a new classifier\n",
    "2. **Fine-tuning**: Allow some or all pre-trained layers to be updated with a small learning rate\n",
    "3. **Gradual Unfreezing**: Start with frozen layers, then gradually unfreeze more layers\n",
    "\n",
    "Let's implement these different approaches and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b597ecd",
   "metadata": {},
   "source": [
    "### 4.1 Feature Extraction (Frozen Backbone)\n",
    "\n",
    "First, let's try feature extraction where we freeze the EfficientNetB5 backbone and only train a new classifier head.\n",
    "\n",
    "In the output of the cell below, note in particular the number of trainable and non-trainable parameters.\n",
    "\n",
    "```\n",
    "1.1 M     Trainable params\n",
    "28.3 M    Non-trainable params\n",
    "```\n",
    "\n",
    "The non-trainable parameters are the frozen parameters of the EfficientNetB5 model. These will not be updated as the model is trained. Only the newly added classifier head, with 1.1 million parameters will be trained.\n",
    "\n",
    "We need the new classifier head because EfficientNetB5 is architected to output the probability that an input image belongs to each of the 1,000 categories of the ImageNet dataset. We need it to output the probability that the input is one of our four categories. We can't use the orginal classifier, because while [bee-eaters](https://en.wikipedia.org/wiki/Bee-eater) (a bird) and bee houses are categories in ImageNet, bees and wasps are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc963510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNetB5 with frozen backbone (feature extraction)\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING EFFICIENTNETB5 - FEATURE EXTRACTION (FROZEN BACKBONE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "frozen_model, frozen_trainer = helpers_01.train_transfer_model(\n",
    "    data_module=data_module,\n",
    "    num_classes=4,\n",
    "    learning_rate=0.001,  # Higher learning rate for new classifier head\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    model_name=\"efficientnet_b5\",\n",
    "    freeze_backbone=True,  # Freeze pre-trained layers\n",
    "    dropout_rate=0.3,\n",
    ")\n",
    "\n",
    "print(\"\\nFrozen backbone model evaluation:\")\n",
    "frozen_results = helpers_01.test_model(data_module, frozen_model, frozen_trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1123f97f",
   "metadata": {},
   "source": [
    "### 4.2 Fine-tuning (Unfrozen Backbone)\n",
    "\n",
    "Now let's try fine-tuning where we allow the entire model to be updated, but with different learning rates for different parts. Again, pay attention to the number of parameters that are trainable and non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef383b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNetB5 with fine-tuning (unfrozen backbone)\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING EFFICIENTNETB5 - FINE-TUNING (UNFROZEN BACKBONE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "finetuned_model, finetuned_trainer = helpers_01.train_transfer_model(\n",
    "    data_module=data_module,\n",
    "    num_classes=4,\n",
    "    learning_rate=0.0001,  # Lower learning rate for fine-tuning\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    model_name=\"efficientnet_b5\",\n",
    "    freeze_backbone=False,  # Allow all layers to be updated\n",
    "    dropout_rate=0.3,\n",
    ")\n",
    "\n",
    "print(\"\\nFine-tuned model evaluation:\")\n",
    "finetuned_results = helpers_01.test_model(\n",
    "    data_module, finetuned_model, finetuned_trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a23fc9",
   "metadata": {},
   "source": [
    "## 5. Comparing Transfer Learning vs Training from Scratch\n",
    "\n",
    "Let's compare our transfer learning results with training from scratch to see the benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b12cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison, let's also train our simple CNN from scratch with the same data\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SIMPLE CNN FROM SCRATCH (FOR COMPARISON)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scratch_model, scratch_trainer = helpers_01.train_model(\n",
    "    data_module=data_module,\n",
    "    num_classes=4,\n",
    "    learning_rate=0.001,\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    input_shape=(3, 224, 224),  # Same input size for fair comparison\n",
    "    dropout_rate=0.5,\n",
    "    conv_padding=1,\n",
    ")\n",
    "\n",
    "print(\"\\nFrom-scratch model evaluation:\")\n",
    "scratch_results = helpers_01.test_model(data_module, scratch_model, scratch_trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a734b9",
   "metadata": {},
   "source": [
    "## 6. Results Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test accuracies from each model\n",
    "models_summary = {\n",
    "    \"EfficientNetB5 (Frozen)\": frozen_results[0][\"test_acc\"],\n",
    "    \"EfficientNetB5 (Fine-tuned)\": finetuned_results[0][\"test_acc\"],\n",
    "    \"Simple CNN (From Scratch)\": scratch_results[0][\"test_acc\"],\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRANSFER LEARNING RESULTS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<30} {'Test Accuracy':<15} {'Training Time':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, accuracy in models_summary.items():\n",
    "    print(f\"{model_name:<30} {accuracy:<15.3f} {'~10 epochs':<15}\")\n",
    "\n",
    "# Create a bar plot comparing accuracies\n",
    "plt.figure(figsize=(12, 6))\n",
    "model_names = list(models_summary.keys())\n",
    "accuracies = list(models_summary.values())\n",
    "\n",
    "colors = [\"lightblue\", \"darkblue\", \"red\"]\n",
    "bars = plt.bar(model_names, accuracies, color=colors)\n",
    "plt.title(\"Transfer Learning vs Training from Scratch: Performance Comparison\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.01,\n",
    "        f\"{acc:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY OBSERVATIONS:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Transfer learning typically achieves higher accuracy faster\")\n",
    "print(\"2. Fine-tuning often outperforms feature extraction\")\n",
    "print(\"3. Pre-trained models start with meaningful features\")\n",
    "print(\"4. Training from scratch requires more data and time to converge\")\n",
    "print(\"5. EfficientNetB5 benefits from ImageNet's diverse feature representations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d7037",
   "metadata": {},
   "source": [
    "## 7. Analyzing What the Model Learned\n",
    "\n",
    "Let's examine what features the pre-trained EfficientNetB5 model is using for our bee vs wasp classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some predictions to understand what the model learned\n",
    "finetuned_model.eval()\n",
    "\n",
    "# Get a batch of validation images\n",
    "val_loader = data_module.val_dataloader()\n",
    "images, labels = next(iter(val_loader))\n",
    "\n",
    "# Get class names\n",
    "class_names, _ = data_module.get_class_info()\n",
    "\n",
    "# Move to same device as model\n",
    "device = next(finetuned_model.parameters()).device\n",
    "images = images.to(device)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = finetuned_model(images)\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    predicted_classes = torch.argmax(outputs, dim=1)\n",
    "\n",
    "# Visualize first 8 predictions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(8):\n",
    "    # Convert image back to displayable format\n",
    "    img = images[i].cpu().numpy().transpose(1, 2, 0)\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Get prediction info\n",
    "    true_class = class_names[labels[i]]\n",
    "    pred_class = class_names[predicted_classes[i]]\n",
    "    confidence = probabilities[i, predicted_classes[i]].item()\n",
    "\n",
    "    # Determine color based on correctness\n",
    "    color = \"green\" if labels[i] == predicted_classes[i] else \"red\"\n",
    "\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(\n",
    "        f\"True: {true_class}\\nPred: {pred_class}\\nConf: {confidence:.2f}\",\n",
    "        color=color,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"EfficientNetB5 Predictions on Validation Data\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc482ed0",
   "metadata": {},
   "source": [
    "## 8. Advanced Transfer Learning: Model Comparison\n",
    "\n",
    "Let's explore how different pre-trained models perform on our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c39f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different pre-trained models\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARING DIFFERENT PRE-TRAINED MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test with a smaller EfficientNet model for comparison\n",
    "print(\"Training EfficientNetB3 (smaller model)...\")\n",
    "efficientb3_model, efficientb3_trainer = helpers_01.train_transfer_model(\n",
    "    data_module=data_module,\n",
    "    num_classes=4,\n",
    "    learning_rate=0.0001,\n",
    "    max_epochs=5,  # Fewer epochs for demonstration\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    model_name=\"efficientnet_b3\",\n",
    "    freeze_backbone=False,\n",
    "    dropout_rate=0.3,\n",
    ")\n",
    "\n",
    "efficientb3_results = helpers_01.test_model(\n",
    "    data_module, efficientb3_model, efficientb3_trainer\n",
    ")\n",
    "\n",
    "# Compare model sizes and performance\n",
    "model_comparison = {\n",
    "    \"EfficientNetB3\": {\n",
    "        \"accuracy\": efficientb3_results[0][\"test_acc\"],\n",
    "        \"params\": \"~12M parameters\",\n",
    "        \"input_size\": \"224x224\",\n",
    "    },\n",
    "    \"EfficientNetB5\": {\n",
    "        \"accuracy\": finetuned_results[0][\"test_acc\"],\n",
    "        \"params\": \"~30M parameters\",\n",
    "        \"input_size\": \"224x224\",\n",
    "    },\n",
    "    \"Simple CNN\": {\n",
    "        \"accuracy\": scratch_results[0][\"test_acc\"],\n",
    "        \"params\": \"~100K parameters\",\n",
    "        \"input_size\": \"224x224\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Model':<15} {'Accuracy':<10} {'Parameters':<15} {'Input Size':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model_name, info in model_comparison.items():\n",
    "    print(\n",
    "        f\"{model_name:<15} {info['accuracy']:<10.3f} {info['params']:<15} {info['input_size']:<12}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d8461",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Best Practices\n",
    "\n",
    "### Key Takeaways from Transfer Learning:\n",
    "\n",
    "1. **Dramatic Performance Improvement**: Pre-trained models typically achieve much better accuracy than training from scratch, especially with limited data.\n",
    "\n",
    "2. **Faster Convergence**: Transfer learning models converge much faster since they start with meaningful features.\n",
    "\n",
    "3. **Resource Efficiency**: Requires less computational resources and training time.\n",
    "\n",
    "4. **Model Size vs Performance**: Larger models (EfficientNetB5) generally perform better than smaller ones (EfficientNetB3), but at the cost of computational requirements.\n",
    "\n",
    "### Best Practices for Transfer Learning:\n",
    "\n",
    "#### **Choosing the Right Approach:**\n",
    "- **Feature Extraction**: When your dataset is small and similar to the pre-training dataset\n",
    "- **Fine-tuning**: When you have sufficient data and computational resources\n",
    "- **Gradual Unfreezing**: For very large models or when training resources are limited\n",
    "\n",
    "#### **Learning Rate Strategy:**\n",
    "- Use **lower learning rates** (0.0001-0.001) for fine-tuning pre-trained layers\n",
    "- Use **higher learning rates** (0.001-0.01) for new classifier heads\n",
    "- Consider **different learning rates** for different parts of the model\n",
    "\n",
    "#### **Data Preprocessing:**\n",
    "- **Match the preprocessing** used during pre-training (normalization, input size)\n",
    "- **Use appropriate input sizes** (224x224 for most ImageNet models)\n",
    "- **Apply similar augmentations** that were used during pre-training\n",
    "\n",
    "#### **Model Selection:**\n",
    "- **EfficientNet**: Great balance of accuracy and efficiency\n",
    "- **ResNet**: Robust and widely used\n",
    "- **Vision Transformer (ViT)**: State-of-the-art for many tasks\n",
    "\n",
    "### When to Use Transfer Learning:\n",
    "\n",
    "✅ **Ideal for:**\n",
    "- Small to medium datasets\n",
    "- Limited computational resources\n",
    "- Quick prototyping and development\n",
    "- Computer vision tasks similar to ImageNet\n",
    "\n",
    "❌ **Consider alternatives when:**\n",
    "- Very large custom datasets available\n",
    "- Domain is very different from pre-training data\n",
    "- Specific architectural requirements\n",
    "\n",
    "Transfer learning is one of the most powerful techniques in modern deep learning, enabling remarkable performance improvements with relatively little additional effort!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a13633",
   "metadata": {},
   "source": [
    "----\n",
    "## Push changes to GitHub <img src=\"images/push_to_github.png\" alt=\"Push to GitHub icon\" align=\"right\" width=150>\n",
    "\n",
    " Remember to **add**, **commit**, and **push** the changes you have made to this notebook to GitHub to keep your repository in sync.\n",
    "\n",
    "In Jupyter, those are done in the git tab on the left. In Google Colab, use File > Save a copy in GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d767a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true) <img src='https://github.com/PracticumAI/deep_learning/blob/main/images/practicumai_deep_learning.png?raw=true' alt='Practicum AI: Deep Learning Foundations icon' align='right' width=50>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Class Imbalance in Data\n",
    "\n",
    "Kevin now understands CNNs and how they work, but his model is still not performing as well as he would like. He's been reading up on some techniques to improve his model's performance and is excited to try them out. \n",
    "\n",
    "In this notebook, we will explore two methods to help mitigate the issues that class imbalance poses: stratification and class weighting.\n",
    "\n",
    "* **Stratification:** Ensures that class frequencies are maintained when making the training and validation datasets. In extreme cases, minority classes can be totally absent from a sampled dataset. But even in the case of less extreme imbalances and larger datasets, stratification can ensure class distributions are the same and help the model train.\n",
    "\n",
    "* **Class weighting:** By default, the probability of any class is assumed to be equal when training a model. In the case of imbalanced classes, that can cause an issue. We can calculate per-class probabilities and use the class weights when training the model.\n",
    "\n",
    "\n",
    "One particularly good resource on this is topic is Ayush Thakur and Aritra Roy Gosthipaty's article [Simple Ways to Tackle Class Imbalance](https://wandb.ai/authors/class-imbalance/reports/Simple-Ways-to-Tackle-Class-Imbalance--VmlldzoxODA3NTk) (Thakur & Gosthipaty). We recommend reading it to learn more about addressing class imbalance in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the libraries we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf   # Import the TensorFlow library, which provides tools for deep learning.\n",
    "import pandas as pd  # Import the pandas library, used for data manipulation and analysis.\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "# Used for data management\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting and visualization.\n",
    "# This line allows for the display of plots directly within the Jupyter notebook interface.\n",
    "%matplotlib inline  \n",
    " \n",
    "# Import Keras libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Import the ImageDataGenerator class from Keras module in TensorFlow.\n",
    "from tensorflow.keras.models import Sequential  # Import the Sequential model: a linear stack of layers from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Dense  # Import the Dense layer: a fully connected neural network layer from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Flatten  # Import the Flatten layer: used to convert input data into a 1D array from Keras module in TensorFlow.\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy  # Import the SparseCategoricalCrossentropy loss function from Keras module in TensorFlow.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import losses\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Import helper functions--most of these were in the cells of the DLF_03_bees_vs_wasps.ipynb notebook.\n",
    "# We moved them out of the notebook to enhance readability. \n",
    "import helpers_01\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the data\n",
    "\n",
    "As before, we'll use our helper function `helpers_01.manage_data` to make sure we have the data and set the `data_path`.\n",
    "\n",
    "In the last notebook, Kevin noticed that his model had a big problem: it thought everything was wasps! Let's explore the data a bit and see if we can figure out why.\n",
    "\n",
    "First let's make a histogram of the number of images in each class. That should give us a good idea of how balanced the dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data at data/bee_vs_wasp.\n"
     ]
    }
   ],
   "source": [
    "# Chech for the data.\n",
    "data_path = helpers_01.manage_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category wasp: 4,943 images, or 43.3% of total images.\n",
      "Category bee: 3,184 images, or 27.9% of total images.\n",
      "Category other_insect: 2,439 images, or 21.4% of total images.\n",
      "Category other_noinsect: 856 images, or 7.5% of total images.\n",
      "************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a histogram of the number of images in each class\n",
    "def make_hist_get_max(data_path):\n",
    "    # Get the class names\n",
    "    class_names = os.listdir(data_path)\n",
    "\n",
    "    # Initialize an empty list to store the number of images in each class\n",
    "    num_images = []\n",
    "\n",
    "    # Loop through each class\n",
    "    for class_name in class_names:\n",
    "        # Get the list of images in the class\n",
    "        images = os.listdir(os.path.join(data_path, class_name))\n",
    "        # Append the number of images in the class to the list\n",
    "        num_images.append(len(images))\n",
    "\n",
    "    # Put the number of images in each class in descending order\n",
    "    num_images, class_names = zip(*sorted(zip(num_images, class_names), reverse=True))\n",
    "\n",
    "    total_images = sum(num_images)\n",
    "    \n",
    "    # Print the number of images in each class\n",
    "    for i in range(len(class_names)):\n",
    "        percentage = (num_images[i] / total_images) * 100\n",
    "        print(f'Category {class_names[i]}: {num_images[i]:,} images, or {percentage:.1f}% of total images.')\n",
    "\n",
    "    print(\"************************************\")       \n",
    "        \n",
    "    # Create a histogram of the number of images in each class\n",
    "    plt.bar(class_names, num_images)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Number of Images in Each Class')\n",
    "    plt.show()\n",
    "\n",
    "    return num_images\n",
    "\n",
    "num_images = make_hist_get_max(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! That's a pretty big class imbalance--there are almost 5,000 wasp images and less than 1,000 other non-insect images. Large class imbalances tend to make models biased towards the majority class. This is likely why Kevin's model was predicting everything as wasps. Let's try to fix this!\n",
    "\n",
    "Part of the issue with imbalanced data is that the algorithm can do fairly well by never predicting the rare class(es).\n",
    "\n",
    "As an example, let's imagine we are looking at a rare disease. If only 5% of the data are from the disease state, a model can be 95% accurate by never predicting disease. That 95% accuracy sounds good, but the model is useless!\n",
    "\n",
    "## A note about class imbalance and the bees vs wasps dataset\n",
    "\n",
    "One important point is that class imbalance can arise from several causes. In the case with our bee and wasp data, the fundamental issue is more of a data quality and collection issue. The real answer to solving the problem has more to do with rethinking the data:\n",
    "\n",
    "* Do the categories really make sense? Probably not--the non-insect category is not very helpful in this case and probably causes more issues than it solves. \n",
    "* Can better data solve the problem? Most likely--we can get more images of bees and other insects.\n",
    "* Are the images we have *quality images*? In many cases, no--many images would be impossible for a human to identify! We have no choice but to trust the labels.\n",
    "\n",
    "Data quality is critical, though not something we will tackle here. Our hyperparameter tuning, stratification, and class weighting will only do so much to improve the results.\n",
    "\n",
    "But, in many cases, class imbalance is an intrinsic part of the data. Rare diseases are a classic example of this. If a disease has an incidence of only 1%, training data for that class will be limited. In these cases, the tools we will cover may be more critical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stratification\n",
    "\n",
    "The first method we will implement is stratification. Stratification ensures that when our dataset is split into training and validation sets, the class frequencies match the frequencies of the original data. This may not seem like a big issue with our dataset, but as we will see, it does help a lot! Ensuring that training and validation class frequencies are the same is important.\n",
    "\n",
    "Let's try this out. We'll use the `train_test_split` function from `sklearn` to split the data into training and validation sets. We'll set the `stratify` parameter to the labels so that the function samples in a stratified manner.\n",
    "\n",
    "We will pass `show_pictures=False` to skip that.\n",
    "\n",
    "You can look in the [`helpers_01.py`](helpers_01.py) file for the full code, but the code for stratifying is here:\n",
    "\n",
    "```python\n",
    " if stratify:  # Use sklearn's train_test_split function to split the data\n",
    "        # into training and testing sets\n",
    "        # Split the data in a stratified manner\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            images, labels, test_size=0.2, stratify=labels\n",
    "        )\n",
    "    else:\n",
    "        # Split the data randomly\n",
    "        X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************\n",
      "Load data:\n",
      "  - Loading the dataset from: data/bee_vs_wasp.\n",
      "  - Using a batch size of: 32.\n",
      "  - Resizing input images to: (80, 80, 3).\n",
      "  - Stratify when sampling? True\n",
      "  - Returning class counts for later use? False\n",
      "******************************************************************\n",
      "\n",
      "For the full dataset:\n",
      "Number of wasp images: 4943, or 43.3%\n",
      "Number of other_insect images: 2439, or 21.4%\n",
      "Number of bee images: 3184, or 27.9%\n",
      "Number of other_noinsect images: 856, or 7.5%\n",
      "Found 9136 validated image filenames belonging to 4 classes.\n",
      "Found 2285 validated image filenames belonging to 4 classes.\n",
      "\n",
      "For the training dataset:\n",
      "Number of wasp images: 3954, or 43.3%\n",
      "Number of other_insect images: 1951, or 21.4%\n",
      "Number of bee images: 2547, or 27.9%\n",
      "Number of other_noinsect images: 685, or 7.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 1 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the data, this updated function changes the code to accommodate stratification\n",
    "# and using class weights. Checkout the file if you want.\n",
    "data_train, data_valid = helpers_01.load_display_data(data_path, batch_size=32, shape=(80,80,3), show_pictures=False, stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "Make model:\n",
      "  - Using the activation function: relu.\n",
      "  - Model will have 4 classes.\n",
      "  - Using a dropout rate of: 0.2.\n",
      "*****************************************************************\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 80, 80, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 20, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1638528   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,732,292\n",
      "Trainable params: 1,732,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 14:24:17.519110: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-03 14:24:18.348244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78902 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# This is the same model we had at the end of notebook 01_bees_vs_wasps.ipynb\n",
    "# The model summary is shown, but model definition code is now moved to the \n",
    "# helpers_02_1.py file.\n",
    "\n",
    "model = helpers_01.make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************\n",
      "Compile and Train the model:\n",
      "  - Using the loss function: categorical_crossentropy.\n",
      "  - Using the optimizer: Adam.\n",
      "  - Using learning rate of: 0.0001.\n",
      "  - Running for 10 epochs.\n",
      "  - Using class weights: {0: 1, 1: 1, 2: 1, 3: 1}.\n",
      "  - Using these callbacks: [].\n",
      "******************************************************************\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 14:24:20.275629: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-03 14:24:21.812933: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 51s 169ms/step - loss: 1.0382 - accuracy: 0.5629 - val_loss: 0.9086 - val_accuracy: 0.6389\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 32s 112ms/step - loss: 0.8289 - accuracy: 0.6697 - val_loss: 0.7802 - val_accuracy: 0.6937\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 32s 112ms/step - loss: 0.7629 - accuracy: 0.6933 - val_loss: 0.7600 - val_accuracy: 0.7007\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 32s 112ms/step - loss: 0.7119 - accuracy: 0.7169 - val_loss: 0.6906 - val_accuracy: 0.7274\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 32s 112ms/step - loss: 0.6848 - accuracy: 0.7310 - val_loss: 0.6671 - val_accuracy: 0.7322\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 32s 112ms/step - loss: 0.6469 - accuracy: 0.7513 - val_loss: 0.6598 - val_accuracy: 0.7352\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 32s 112ms/step - loss: 0.6269 - accuracy: 0.7569 - val_loss: 0.6266 - val_accuracy: 0.7567\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 32s 112ms/step - loss: 0.6017 - accuracy: 0.7662 - val_loss: 0.6253 - val_accuracy: 0.7584\n",
      "Epoch 9/10\n",
      "191/286 [===================>..........] - ETA: 8s - loss: 0.5797 - accuracy: 0.7750Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/scratch/local/46175783/ipykernel_2227093/3143685394.py\", line 5, in <cell line: 5>\n",
      "    model, history = helpers_01.compile_train_model(data_train, data_valid, model,\n",
      "  File \"/blue/ufhpc/magitz/PracticumAI/computer_vision/helpers_01.py\", line 396, in compile_train_model\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/training.py\", line 1216, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 910, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 942, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3130, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 1959, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 598, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 58, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/apps/tensorflow/2.7.0/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# compile and train the model\n",
    "# Due to change in dataset format, we change to categorical_crossentropy loss. \n",
    "# This is the same loss function except in the format of the labels\n",
    "\n",
    "model, history = helpers_01.compile_train_model(data_train, data_valid, model, \n",
    "                        log_name='stratify', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "helpers_01.evaluate_model(data_valid, model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class weighting\n",
    "\n",
    "The next method we will implement is class weighting. As Thakur & Gosthipaty write:\n",
    "> One of the easiest ways to counter class imbalance is to use class weights wherein we give different weightage to different classes. The number of samples in the classes is considered while computing the class weights. We apply more significant weight to a minority class, which places more emphasis on that class. The classifier thus learns equally from both the classes. [Their example had only two classes]\n",
    ">\n",
    "> Class weights regularize the loss function. By misclassifying the minority class, a higher loss is incurred by the model since the minority class has a higher weight. This forces the model to learn representations for the minority class. This, however, comes at a price of slightly reduced performance for the majority class.\n",
    "\n",
    "Note that they were dealing with two classes; here, we have four. Our code will handle datasets with different numbers of classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train, data_valid, cls_counts = helpers_01.load_display_data(data_path, \n",
    "                batch_size=32, shape=(80,80,3), show_pictures=False, \n",
    "                stratify=True, return_cls_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Make our model\n",
    "We'll make a fresh model to test out our class weighting method. The architecture will be the same as the previous CNNs we've made with a few DropOut layers to help prevent overfitting. The code for the model is in the `helpers_02_1.py` file to keep this notebook clean.\n",
    "\n",
    "One reason to create a fresh model is that we need to clear the session to ensure that the model is created from scratch. If we don't do this, the model will be created with the weights from the previous model. This is not what we want! There are other ways to handle this, but this is way is pretty simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the model\n",
    "\n",
    "model = helpers_01.make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compile and train the model\n",
    "\n",
    "This time we will have both stratification and class weighting turned on. Finger's crossed that this will help our model with its wasp obsession!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model, history = helpers_01.compile_train_model(data_train, data_valid, model,\n",
    "                        weights=cls_counts, log_name='weights',\n",
    "                        loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Evaluate the model\n",
    "\n",
    "Now that we have trained our model, let's evaluate how it performs compared to the previous model that only used stratification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "helpers_01.evaluate_model(data_valid, model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "From the evaluation data above, stratification alone was more helpful than stratification and class weighting combined. Of note, in both scenarios training and validation accuracy we both improving together. This is a good sign that the model is learning and not just memorizing the training data. When a model is still showing improvement in both training and validation, a simple thing to try is to train it for more epochs.\n",
    "\n",
    "In addition to training for more epochs, what else could we do to improve the model? If you have time, experiment with different hyperparameters!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
